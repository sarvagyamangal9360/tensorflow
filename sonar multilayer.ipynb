{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as n\n",
    "import pandas as p\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"G://programs//sonar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "                6           7           8           9  ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_database():\n",
    "    X=df[df.columns[1:60]].values\n",
    "    y=df[df.columns[60]]\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y=encoder.transform(y)\n",
    "    Y=one_hot_encode(y)\n",
    "    return(X,Y,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(features):\n",
    "    mu=n.mean(features,axis=0)         #normalize the features of the dataset\n",
    "    sigma=n.std(features,axis=0)\n",
    "    normalize_features=(features-mu)/sigma\n",
    "    return(normalize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_bias_reshape(features):\n",
    "    n_training_samples=features.shape[0]\n",
    "    n_dim=features.shape[1]\n",
    "    features=np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim+1])\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(n.unique(labels))\n",
    "    one_hot_encode=n.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[n.arange(n_labels),labels]=1\n",
    "    return(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0371 0.0428 0.0207 ... 0.0084 0.009  0.0032]\n",
      " [0.0523 0.0843 0.0689 ... 0.0049 0.0052 0.0044]\n",
      " [0.0582 0.1099 0.1083 ... 0.0164 0.0095 0.0078]\n",
      " ...\n",
      " [0.0437 0.018  0.0292 ... 0.0138 0.0077 0.0031]\n",
      " [0.0353 0.049  0.0608 ... 0.0079 0.0036 0.0048]\n",
      " [0.0363 0.0136 0.0272 ... 0.0036 0.0061 0.0115]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 59)\n",
      "(42, 59)\n",
      "(166, 2)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=59\n",
    "n_output=2\n",
    "n_hidden_1=110\n",
    "n_hidden_2=110\n",
    "n_hidden_3=110\n",
    "n_hidden_4=110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,n_input])\n",
    "y_=tf.placeholder(tf.float32,[None,n_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.random_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.random_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_4,n_output]))\n",
    "}\n",
    "bias={\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.random_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.random_normal([n_output]))\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,bias):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),bias['b1'])\n",
    "    layer_1=tf.nn.relu(layer_1)\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),bias['b2'])\n",
    "    layer_2=tf.nn.relu(layer_2)\n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),bias['b3'])\n",
    "    layer_3=tf.nn.relu(layer_3)\n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),bias['b4'])\n",
    "    layer_4=tf.nn.relu(layer_4)\n",
    "    output=tf.matmul(layer_3,weights['out'])+bias['out']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= multilayer_perceptron(x,weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "training_epochs=100\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 3512.4993\n",
      "0.5120482\n",
      "epoch: 1 - cost: 1027.0059\n",
      "0.5120482\n",
      "epoch: 2 - cost: 1293.9109\n",
      "0.48795182\n",
      "epoch: 3 - cost: 1309.4973\n",
      "0.48795182\n",
      "epoch: 4 - cost: 611.0908\n",
      "0.48795182\n",
      "epoch: 5 - cost: 157.36911\n",
      "0.6204819\n",
      "epoch: 6 - cost: 421.72977\n",
      "0.5421687\n",
      "epoch: 7 - cost: 346.90707\n",
      "0.5421687\n",
      "epoch: 8 - cost: 94.73073\n",
      "0.6325301\n",
      "epoch: 9 - cost: 279.8992\n",
      "0.5421687\n",
      "epoch: 10 - cost: 251.29396\n",
      "0.52409637\n",
      "epoch: 11 - cost: 72.38686\n",
      "0.59638554\n",
      "epoch: 12 - cost: 72.68094\n",
      "0.6626506\n",
      "epoch: 13 - cost: 101.8444\n",
      "0.560241\n",
      "epoch: 14 - cost: 51.930325\n",
      "0.64457834\n",
      "epoch: 15 - cost: 40.889088\n",
      "0.70481926\n",
      "epoch: 16 - cost: 71.092606\n",
      "0.60240966\n",
      "epoch: 17 - cost: 38.70157\n",
      "0.6927711\n",
      "epoch: 18 - cost: 20.408958\n",
      "0.76506025\n",
      "epoch: 19 - cost: 51.03145\n",
      "0.61445785\n",
      "epoch: 20 - cost: 34.62835\n",
      "0.686747\n",
      "epoch: 21 - cost: 14.279723\n",
      "0.8192771\n",
      "epoch: 22 - cost: 27.125565\n",
      "0.70481926\n",
      "epoch: 23 - cost: 26.493511\n",
      "0.6927711\n",
      "epoch: 24 - cost: 11.197099\n",
      "0.8313253\n",
      "epoch: 25 - cost: 19.13567\n",
      "0.77710843\n",
      "epoch: 26 - cost: 22.704771\n",
      "0.76506025\n",
      "epoch: 27 - cost: 13.331403\n",
      "0.78313255\n",
      "epoch: 28 - cost: 7.5024886\n",
      "0.8313253\n",
      "epoch: 29 - cost: 16.899364\n",
      "0.6927711\n",
      "epoch: 30 - cost: 9.206264\n",
      "0.8072289\n",
      "epoch: 31 - cost: 6.3893538\n",
      "0.8614458\n",
      "epoch: 32 - cost: 11.550614\n",
      "0.8012048\n",
      "epoch: 33 - cost: 11.17995\n",
      "0.8012048\n",
      "epoch: 34 - cost: 5.984497\n",
      "0.8433735\n",
      "epoch: 35 - cost: 6.035866\n",
      "0.8373494\n",
      "epoch: 36 - cost: 8.057172\n",
      "0.8012048\n",
      "epoch: 37 - cost: 3.6091099\n",
      "0.8915663\n",
      "epoch: 38 - cost: 3.3148708\n",
      "0.8795181\n",
      "epoch: 39 - cost: 4.770889\n",
      "0.8313253\n",
      "epoch: 40 - cost: 3.8765361\n",
      "0.8493976\n",
      "epoch: 41 - cost: 2.5698771\n",
      "0.8674699\n",
      "epoch: 42 - cost: 3.8001792\n",
      "0.8614458\n",
      "epoch: 43 - cost: 2.040245\n",
      "0.89759034\n",
      "epoch: 44 - cost: 1.6203226\n",
      "0.88554215\n",
      "epoch: 45 - cost: 2.0679238\n",
      "0.8614458\n",
      "epoch: 46 - cost: 1.1659588\n",
      "0.91566265\n",
      "epoch: 47 - cost: 1.4199852\n",
      "0.9096386\n",
      "epoch: 48 - cost: 1.4996067\n",
      "0.91566265\n",
      "epoch: 49 - cost: 0.83512694\n",
      "0.91566265\n",
      "epoch: 50 - cost: 1.1256075\n",
      "0.90361446\n",
      "epoch: 51 - cost: 0.9142463\n",
      "0.90361446\n",
      "epoch: 52 - cost: 0.74430233\n",
      "0.939759\n",
      "epoch: 53 - cost: 1.0169153\n",
      "0.92771083\n",
      "epoch: 54 - cost: 0.5628575\n",
      "0.94578314\n",
      "epoch: 55 - cost: 0.8264241\n",
      "0.91566265\n",
      "epoch: 56 - cost: 0.48938134\n",
      "0.92771083\n",
      "epoch: 57 - cost: 0.2818598\n",
      "0.97590363\n",
      "epoch: 58 - cost: 0.4903807\n",
      "0.9578313\n",
      "epoch: 59 - cost: 0.40521857\n",
      "0.96385545\n",
      "epoch: 60 - cost: 0.22485177\n",
      "0.9879518\n",
      "epoch: 61 - cost: 0.15947756\n",
      "0.96385545\n",
      "epoch: 62 - cost: 0.39528137\n",
      "0.93373495\n",
      "epoch: 63 - cost: 0.09174817\n",
      "0.9879518\n",
      "epoch: 64 - cost: 0.1609492\n",
      "0.9879518\n",
      "epoch: 65 - cost: 0.17940177\n",
      "0.9879518\n",
      "epoch: 66 - cost: 0.14806052\n",
      "0.9879518\n",
      "epoch: 67 - cost: 0.062059723\n",
      "0.9879518\n",
      "epoch: 68 - cost: 0.04083064\n",
      "0.9939759\n",
      "epoch: 69 - cost: 0.10352376\n",
      "0.97590363\n",
      "epoch: 70 - cost: 0.03644545\n",
      "0.9939759\n",
      "epoch: 71 - cost: 0.033469748\n",
      "0.9819277\n",
      "epoch: 72 - cost: 0.038208302\n",
      "0.9819277\n",
      "epoch: 73 - cost: 0.0009352658\n",
      "1.0\n",
      "epoch: 74 - cost: 0.0007306877\n",
      "1.0\n",
      "epoch: 75 - cost: 0.00077726063\n",
      "1.0\n",
      "epoch: 76 - cost: 0.0015525927\n",
      "1.0\n",
      "epoch: 77 - cost: 0.0026021418\n",
      "1.0\n",
      "epoch: 78 - cost: 0.0019219042\n",
      "1.0\n",
      "epoch: 79 - cost: 0.00072365365\n",
      "1.0\n",
      "epoch: 80 - cost: 0.00025381643\n",
      "1.0\n",
      "epoch: 81 - cost: 0.0005196576\n",
      "1.0\n",
      "epoch: 82 - cost: 0.0026032128\n",
      "1.0\n",
      "epoch: 83 - cost: 0.0025549468\n",
      "1.0\n",
      "epoch: 84 - cost: 0.00055399694\n",
      "1.0\n",
      "epoch: 85 - cost: 0.00023270008\n",
      "1.0\n",
      "epoch: 86 - cost: 0.00053374504\n",
      "1.0\n",
      "epoch: 87 - cost: 0.0008389985\n",
      "1.0\n",
      "epoch: 88 - cost: 0.000636467\n",
      "1.0\n",
      "epoch: 89 - cost: 0.00035502957\n",
      "1.0\n",
      "epoch: 90 - cost: 0.00017870883\n",
      "1.0\n",
      "epoch: 91 - cost: 8.480291e-05\n",
      "1.0\n",
      "epoch: 92 - cost: 4.2693773e-05\n",
      "1.0\n",
      "epoch: 93 - cost: 2.468692e-05\n",
      "1.0\n",
      "epoch: 94 - cost: 1.7604862e-05\n",
      "1.0\n",
      "epoch: 95 - cost: 1.5694246e-05\n",
      "1.0\n",
      "epoch: 96 - cost: 1.6479768e-05\n",
      "1.0\n",
      "epoch: 97 - cost: 1.8827084e-05\n",
      "1.0\n",
      "epoch: 98 - cost: 2.2133692e-05\n",
      "1.0\n",
      "epoch: 99 - cost: 2.5972347e-05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(optimizer,feed_dict={x:X_train,y_:y_train})\n",
    "    cost=sess.run(loss,feed_dict={x:X_train,y_:y_train})\n",
    "    cost_history=n.append(cost_history,cost)\n",
    "    print('epoch:',epoch,'-','cost:',cost)    \n",
    "    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(sess.run(accuracy,feed_dict=({x: X_train, y_: y_train})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy,feed_dict=({x: X_train, y: y_train})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22c4a063978>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
